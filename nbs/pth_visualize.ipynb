{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Parameter: patch_embed.seq.0.c.weight, Shape: torch.Size([32, 3, 1, 1])\n",
      "Parameter: patch_embed.seq.0.bn.weight, Shape: torch.Size([32])\n",
      "Parameter: patch_embed.seq.0.bn.bias, Shape: torch.Size([32])\n",
      "Parameter: patch_embed.seq.0.bn.running_mean, Shape: torch.Size([32])\n",
      "Parameter: patch_embed.seq.0.bn.running_var, Shape: torch.Size([32])\n",
      "Parameter: patch_embed.seq.0.bn.num_batches_tracked, Shape: torch.Size([])\n",
      "Parameter: patch_embed.seq.2.c.weight, Shape: torch.Size([64, 32, 1, 1])\n",
      "Parameter: patch_embed.seq.2.bn.weight, Shape: torch.Size([64])\n",
      "Parameter: patch_embed.seq.2.bn.bias, Shape: torch.Size([64])\n",
      "Parameter: patch_embed.seq.2.bn.running_mean, Shape: torch.Size([64])\n",
      "Parameter: patch_embed.seq.2.bn.running_var, Shape: torch.Size([64])\n",
      "Parameter: patch_embed.seq.2.bn.num_batches_tracked, Shape: torch.Size([])\n",
      "Parameter: layers.0.blocks.0.conv1.c.weight, Shape: torch.Size([256, 64, 1, 1])\n",
      "Parameter: layers.0.blocks.0.conv1.bn.weight, Shape: torch.Size([256])\n",
      "Parameter: layers.0.blocks.0.conv1.bn.bias, Shape: torch.Size([256])\n",
      "Parameter: layers.0.blocks.0.conv1.bn.running_mean, Shape: torch.Size([256])\n",
      "Parameter: layers.0.blocks.0.conv1.bn.running_var, Shape: torch.Size([256])\n",
      "Parameter: layers.0.blocks.0.conv1.bn.num_batches_tracked, Shape: torch.Size([])\n",
      "Parameter: layers.0.blocks.0.conv2.c.weight, Shape: torch.Size([256, 1, 3, 3])\n",
      "Parameter: layers.0.blocks.0.conv2.bn.weight, Shape: torch.Size([256])\n",
      "Parameter: layers.0.blocks.0.conv2.bn.bias, Shape: torch.Size([256])\n",
      "Parameter: layers.0.blocks.0.conv2.bn.running_mean, Shape: torch.Size([256])\n",
      "Parameter: layers.0.blocks.0.conv2.bn.running_var, Shape: torch.Size([256])\n",
      "Parameter: layers.0.blocks.0.conv2.bn.num_batches_tracked, Shape: torch.Size([])\n",
      "Parameter: layers.0.blocks.0.conv3.c.weight, Shape: torch.Size([64, 256, 1, 1])\n",
      "Parameter: layers.0.blocks.0.conv3.bn.weight, Shape: torch.Size([64])\n",
      "Parameter: layers.0.blocks.0.conv3.bn.bias, Shape: torch.Size([64])\n",
      "Parameter: layers.0.blocks.0.conv3.bn.running_mean, Shape: torch.Size([64])\n",
      "Parameter: layers.0.blocks.0.conv3.bn.running_var, Shape: torch.Size([64])\n",
      "Parameter: layers.0.blocks.0.conv3.bn.num_batches_tracked, Shape: torch.Size([])\n",
      "Parameter: layers.0.blocks.1.conv1.c.weight, Shape: torch.Size([256, 64, 1, 1])\n",
      "Parameter: layers.0.blocks.1.conv1.bn.weight, Shape: torch.Size([256])\n",
      "Parameter: layers.0.blocks.1.conv1.bn.bias, Shape: torch.Size([256])\n",
      "Parameter: layers.0.blocks.1.conv1.bn.running_mean, Shape: torch.Size([256])\n",
      "Parameter: layers.0.blocks.1.conv1.bn.running_var, Shape: torch.Size([256])\n",
      "Parameter: layers.0.blocks.1.conv1.bn.num_batches_tracked, Shape: torch.Size([])\n",
      "Parameter: layers.0.blocks.1.conv2.c.weight, Shape: torch.Size([256, 1, 3, 3])\n",
      "Parameter: layers.0.blocks.1.conv2.bn.weight, Shape: torch.Size([256])\n",
      "Parameter: layers.0.blocks.1.conv2.bn.bias, Shape: torch.Size([256])\n",
      "Parameter: layers.0.blocks.1.conv2.bn.running_mean, Shape: torch.Size([256])\n",
      "Parameter: layers.0.blocks.1.conv2.bn.running_var, Shape: torch.Size([256])\n",
      "Parameter: layers.0.blocks.1.conv2.bn.num_batches_tracked, Shape: torch.Size([])\n",
      "Parameter: layers.0.blocks.1.conv3.c.weight, Shape: torch.Size([64, 256, 1, 1])\n",
      "Parameter: layers.0.blocks.1.conv3.bn.weight, Shape: torch.Size([64])\n",
      "Parameter: layers.0.blocks.1.conv3.bn.bias, Shape: torch.Size([64])\n",
      "Parameter: layers.0.blocks.1.conv3.bn.running_mean, Shape: torch.Size([64])\n",
      "Parameter: layers.0.blocks.1.conv3.bn.running_var, Shape: torch.Size([64])\n",
      "Parameter: layers.0.blocks.1.conv3.bn.num_batches_tracked, Shape: torch.Size([])\n",
      "Parameter: layers.0.downsample.conv1.c.weight, Shape: torch.Size([128, 64, 1, 1])\n",
      "Parameter: layers.0.downsample.conv1.bn.weight, Shape: torch.Size([128])\n",
      "Parameter: layers.0.downsample.conv1.bn.bias, Shape: torch.Size([128])\n",
      "Parameter: layers.0.downsample.conv1.bn.running_mean, Shape: torch.Size([128])\n",
      "Parameter: layers.0.downsample.conv1.bn.running_var, Shape: torch.Size([128])\n",
      "Parameter: layers.0.downsample.conv1.bn.num_batches_tracked, Shape: torch.Size([])\n",
      "Parameter: layers.0.downsample.conv2.c.weight, Shape: torch.Size([128, 1, 3, 3])\n",
      "Parameter: layers.0.downsample.conv2.bn.weight, Shape: torch.Size([128])\n",
      "Parameter: layers.0.downsample.conv2.bn.bias, Shape: torch.Size([128])\n",
      "Parameter: layers.0.downsample.conv2.bn.running_mean, Shape: torch.Size([128])\n",
      "Parameter: layers.0.downsample.conv2.bn.running_var, Shape: torch.Size([128])\n",
      "Parameter: layers.0.downsample.conv2.bn.num_batches_tracked, Shape: torch.Size([])\n",
      "Parameter: layers.0.downsample.conv3.c.weight, Shape: torch.Size([128, 128, 1, 1])\n",
      "Parameter: layers.0.downsample.conv3.bn.weight, Shape: torch.Size([128])\n",
      "Parameter: layers.0.downsample.conv3.bn.bias, Shape: torch.Size([128])\n",
      "Parameter: layers.0.downsample.conv3.bn.running_mean, Shape: torch.Size([128])\n",
      "Parameter: layers.0.downsample.conv3.bn.running_var, Shape: torch.Size([128])\n",
      "Parameter: layers.0.downsample.conv3.bn.num_batches_tracked, Shape: torch.Size([])\n",
      "Parameter: layers.1.blocks.0.attn.attention_biases, Shape: torch.Size([4, 49])\n",
      "Parameter: layers.1.blocks.0.attn.norm.weight, Shape: torch.Size([128])\n",
      "Parameter: layers.1.blocks.0.attn.norm.bias, Shape: torch.Size([128])\n",
      "Parameter: layers.1.blocks.0.attn.qkv.weight, Shape: torch.Size([384, 128])\n",
      "Parameter: layers.1.blocks.0.attn.qkv.bias, Shape: torch.Size([384])\n",
      "Parameter: layers.1.blocks.0.attn.proj.weight, Shape: torch.Size([128, 128])\n",
      "Parameter: layers.1.blocks.0.attn.proj.bias, Shape: torch.Size([128])\n",
      "Parameter: layers.1.blocks.0.mlp.norm.weight, Shape: torch.Size([128])\n",
      "Parameter: layers.1.blocks.0.mlp.norm.bias, Shape: torch.Size([128])\n",
      "Parameter: layers.1.blocks.0.mlp.fc1.weight, Shape: torch.Size([512, 128])\n",
      "Parameter: layers.1.blocks.0.mlp.fc1.bias, Shape: torch.Size([512])\n",
      "Parameter: layers.1.blocks.0.mlp.fc2.weight, Shape: torch.Size([128, 512])\n",
      "Parameter: layers.1.blocks.0.mlp.fc2.bias, Shape: torch.Size([128])\n",
      "Parameter: layers.1.blocks.0.local_conv.c.weight, Shape: torch.Size([128, 1, 3, 3])\n",
      "Parameter: layers.1.blocks.0.local_conv.bn.weight, Shape: torch.Size([128])\n",
      "Parameter: layers.1.blocks.0.local_conv.bn.bias, Shape: torch.Size([128])\n",
      "Parameter: layers.1.blocks.0.local_conv.bn.running_mean, Shape: torch.Size([128])\n",
      "Parameter: layers.1.blocks.0.local_conv.bn.running_var, Shape: torch.Size([128])\n",
      "Parameter: layers.1.blocks.0.local_conv.bn.num_batches_tracked, Shape: torch.Size([])\n",
      "Parameter: layers.1.blocks.1.attn.attention_biases, Shape: torch.Size([4, 49])\n",
      "Parameter: layers.1.blocks.1.attn.norm.weight, Shape: torch.Size([128])\n",
      "Parameter: layers.1.blocks.1.attn.norm.bias, Shape: torch.Size([128])\n",
      "Parameter: layers.1.blocks.1.attn.qkv.weight, Shape: torch.Size([384, 128])\n",
      "Parameter: layers.1.blocks.1.attn.qkv.bias, Shape: torch.Size([384])\n",
      "Parameter: layers.1.blocks.1.attn.proj.weight, Shape: torch.Size([128, 128])\n",
      "Parameter: layers.1.blocks.1.attn.proj.bias, Shape: torch.Size([128])\n",
      "Parameter: layers.1.blocks.1.mlp.norm.weight, Shape: torch.Size([128])\n",
      "Parameter: layers.1.blocks.1.mlp.norm.bias, Shape: torch.Size([128])\n",
      "Parameter: layers.1.blocks.1.mlp.fc1.weight, Shape: torch.Size([512, 128])\n",
      "Parameter: layers.1.blocks.1.mlp.fc1.bias, Shape: torch.Size([512])\n",
      "Parameter: layers.1.blocks.1.mlp.fc2.weight, Shape: torch.Size([128, 512])\n",
      "Parameter: layers.1.blocks.1.mlp.fc2.bias, Shape: torch.Size([128])\n",
      "Parameter: layers.1.blocks.1.local_conv.c.weight, Shape: torch.Size([128, 1, 3, 3])\n",
      "Parameter: layers.1.blocks.1.local_conv.bn.weight, Shape: torch.Size([128])\n",
      "Parameter: layers.1.blocks.1.local_conv.bn.bias, Shape: torch.Size([128])\n",
      "Parameter: layers.1.blocks.1.local_conv.bn.running_mean, Shape: torch.Size([128])\n",
      "Parameter: layers.1.blocks.1.local_conv.bn.running_var, Shape: torch.Size([128])\n",
      "Parameter: layers.1.blocks.1.local_conv.bn.num_batches_tracked, Shape: torch.Size([])\n",
      "Parameter: layers.1.downsample.conv1.c.weight, Shape: torch.Size([160, 128, 1, 1])\n",
      "Parameter: layers.1.downsample.conv1.bn.weight, Shape: torch.Size([160])\n",
      "Parameter: layers.1.downsample.conv1.bn.bias, Shape: torch.Size([160])\n",
      "Parameter: layers.1.downsample.conv1.bn.running_mean, Shape: torch.Size([160])\n",
      "Parameter: layers.1.downsample.conv1.bn.running_var, Shape: torch.Size([160])\n",
      "Parameter: layers.1.downsample.conv1.bn.num_batches_tracked, Shape: torch.Size([])\n",
      "Parameter: layers.1.downsample.conv2.c.weight, Shape: torch.Size([160, 1, 3, 3])\n",
      "Parameter: layers.1.downsample.conv2.bn.weight, Shape: torch.Size([160])\n",
      "Parameter: layers.1.downsample.conv2.bn.bias, Shape: torch.Size([160])\n",
      "Parameter: layers.1.downsample.conv2.bn.running_mean, Shape: torch.Size([160])\n",
      "Parameter: layers.1.downsample.conv2.bn.running_var, Shape: torch.Size([160])\n",
      "Parameter: layers.1.downsample.conv2.bn.num_batches_tracked, Shape: torch.Size([])\n",
      "Parameter: layers.1.downsample.conv3.c.weight, Shape: torch.Size([160, 160, 1, 1])\n",
      "Parameter: layers.1.downsample.conv3.bn.weight, Shape: torch.Size([160])\n",
      "Parameter: layers.1.downsample.conv3.bn.bias, Shape: torch.Size([160])\n",
      "Parameter: layers.1.downsample.conv3.bn.running_mean, Shape: torch.Size([160])\n",
      "Parameter: layers.1.downsample.conv3.bn.running_var, Shape: torch.Size([160])\n",
      "Parameter: layers.1.downsample.conv3.bn.num_batches_tracked, Shape: torch.Size([])\n",
      "Parameter: layers.2.blocks.0.attn.attention_biases, Shape: torch.Size([5, 196])\n",
      "Parameter: layers.2.blocks.0.attn.norm.weight, Shape: torch.Size([160])\n",
      "Parameter: layers.2.blocks.0.attn.norm.bias, Shape: torch.Size([160])\n",
      "Parameter: layers.2.blocks.0.attn.qkv.weight, Shape: torch.Size([480, 160])\n",
      "Parameter: layers.2.blocks.0.attn.qkv.bias, Shape: torch.Size([480])\n",
      "Parameter: layers.2.blocks.0.attn.proj.weight, Shape: torch.Size([160, 160])\n",
      "Parameter: layers.2.blocks.0.attn.proj.bias, Shape: torch.Size([160])\n",
      "Parameter: layers.2.blocks.0.mlp.norm.weight, Shape: torch.Size([160])\n",
      "Parameter: layers.2.blocks.0.mlp.norm.bias, Shape: torch.Size([160])\n",
      "Parameter: layers.2.blocks.0.mlp.fc1.weight, Shape: torch.Size([640, 160])\n",
      "Parameter: layers.2.blocks.0.mlp.fc1.bias, Shape: torch.Size([640])\n",
      "Parameter: layers.2.blocks.0.mlp.fc2.weight, Shape: torch.Size([160, 640])\n",
      "Parameter: layers.2.blocks.0.mlp.fc2.bias, Shape: torch.Size([160])\n",
      "Parameter: layers.2.blocks.0.local_conv.c.weight, Shape: torch.Size([160, 1, 3, 3])\n",
      "Parameter: layers.2.blocks.0.local_conv.bn.weight, Shape: torch.Size([160])\n",
      "Parameter: layers.2.blocks.0.local_conv.bn.bias, Shape: torch.Size([160])\n",
      "Parameter: layers.2.blocks.0.local_conv.bn.running_mean, Shape: torch.Size([160])\n",
      "Parameter: layers.2.blocks.0.local_conv.bn.running_var, Shape: torch.Size([160])\n",
      "Parameter: layers.2.blocks.0.local_conv.bn.num_batches_tracked, Shape: torch.Size([])\n",
      "Parameter: layers.2.blocks.1.attn.attention_biases, Shape: torch.Size([5, 196])\n",
      "Parameter: layers.2.blocks.1.attn.norm.weight, Shape: torch.Size([160])\n",
      "Parameter: layers.2.blocks.1.attn.norm.bias, Shape: torch.Size([160])\n",
      "Parameter: layers.2.blocks.1.attn.qkv.weight, Shape: torch.Size([480, 160])\n",
      "Parameter: layers.2.blocks.1.attn.qkv.bias, Shape: torch.Size([480])\n",
      "Parameter: layers.2.blocks.1.attn.proj.weight, Shape: torch.Size([160, 160])\n",
      "Parameter: layers.2.blocks.1.attn.proj.bias, Shape: torch.Size([160])\n",
      "Parameter: layers.2.blocks.1.mlp.norm.weight, Shape: torch.Size([160])\n",
      "Parameter: layers.2.blocks.1.mlp.norm.bias, Shape: torch.Size([160])\n",
      "Parameter: layers.2.blocks.1.mlp.fc1.weight, Shape: torch.Size([640, 160])\n",
      "Parameter: layers.2.blocks.1.mlp.fc1.bias, Shape: torch.Size([640])\n",
      "Parameter: layers.2.blocks.1.mlp.fc2.weight, Shape: torch.Size([160, 640])\n",
      "Parameter: layers.2.blocks.1.mlp.fc2.bias, Shape: torch.Size([160])\n",
      "Parameter: layers.2.blocks.1.local_conv.c.weight, Shape: torch.Size([160, 1, 3, 3])\n",
      "Parameter: layers.2.blocks.1.local_conv.bn.weight, Shape: torch.Size([160])\n",
      "Parameter: layers.2.blocks.1.local_conv.bn.bias, Shape: torch.Size([160])\n",
      "Parameter: layers.2.blocks.1.local_conv.bn.running_mean, Shape: torch.Size([160])\n",
      "Parameter: layers.2.blocks.1.local_conv.bn.running_var, Shape: torch.Size([160])\n",
      "Parameter: layers.2.blocks.1.local_conv.bn.num_batches_tracked, Shape: torch.Size([])\n",
      "Parameter: layers.2.blocks.2.attn.attention_biases, Shape: torch.Size([5, 196])\n",
      "Parameter: layers.2.blocks.2.attn.norm.weight, Shape: torch.Size([160])\n",
      "Parameter: layers.2.blocks.2.attn.norm.bias, Shape: torch.Size([160])\n",
      "Parameter: layers.2.blocks.2.attn.qkv.weight, Shape: torch.Size([480, 160])\n",
      "Parameter: layers.2.blocks.2.attn.qkv.bias, Shape: torch.Size([480])\n",
      "Parameter: layers.2.blocks.2.attn.proj.weight, Shape: torch.Size([160, 160])\n",
      "Parameter: layers.2.blocks.2.attn.proj.bias, Shape: torch.Size([160])\n",
      "Parameter: layers.2.blocks.2.mlp.norm.weight, Shape: torch.Size([160])\n",
      "Parameter: layers.2.blocks.2.mlp.norm.bias, Shape: torch.Size([160])\n",
      "Parameter: layers.2.blocks.2.mlp.fc1.weight, Shape: torch.Size([640, 160])\n",
      "Parameter: layers.2.blocks.2.mlp.fc1.bias, Shape: torch.Size([640])\n",
      "Parameter: layers.2.blocks.2.mlp.fc2.weight, Shape: torch.Size([160, 640])\n",
      "Parameter: layers.2.blocks.2.mlp.fc2.bias, Shape: torch.Size([160])\n",
      "Parameter: layers.2.blocks.2.local_conv.c.weight, Shape: torch.Size([160, 1, 3, 3])\n",
      "Parameter: layers.2.blocks.2.local_conv.bn.weight, Shape: torch.Size([160])\n",
      "Parameter: layers.2.blocks.2.local_conv.bn.bias, Shape: torch.Size([160])\n",
      "Parameter: layers.2.blocks.2.local_conv.bn.running_mean, Shape: torch.Size([160])\n",
      "Parameter: layers.2.blocks.2.local_conv.bn.running_var, Shape: torch.Size([160])\n",
      "Parameter: layers.2.blocks.2.local_conv.bn.num_batches_tracked, Shape: torch.Size([])\n",
      "Parameter: layers.2.blocks.3.attn.attention_biases, Shape: torch.Size([5, 196])\n",
      "Parameter: layers.2.blocks.3.attn.norm.weight, Shape: torch.Size([160])\n",
      "Parameter: layers.2.blocks.3.attn.norm.bias, Shape: torch.Size([160])\n",
      "Parameter: layers.2.blocks.3.attn.qkv.weight, Shape: torch.Size([480, 160])\n",
      "Parameter: layers.2.blocks.3.attn.qkv.bias, Shape: torch.Size([480])\n",
      "Parameter: layers.2.blocks.3.attn.proj.weight, Shape: torch.Size([160, 160])\n",
      "Parameter: layers.2.blocks.3.attn.proj.bias, Shape: torch.Size([160])\n",
      "Parameter: layers.2.blocks.3.mlp.norm.weight, Shape: torch.Size([160])\n",
      "Parameter: layers.2.blocks.3.mlp.norm.bias, Shape: torch.Size([160])\n",
      "Parameter: layers.2.blocks.3.mlp.fc1.weight, Shape: torch.Size([640, 160])\n",
      "Parameter: layers.2.blocks.3.mlp.fc1.bias, Shape: torch.Size([640])\n",
      "Parameter: layers.2.blocks.3.mlp.fc2.weight, Shape: torch.Size([160, 640])\n",
      "Parameter: layers.2.blocks.3.mlp.fc2.bias, Shape: torch.Size([160])\n",
      "Parameter: layers.2.blocks.3.local_conv.c.weight, Shape: torch.Size([160, 1, 3, 3])\n",
      "Parameter: layers.2.blocks.3.local_conv.bn.weight, Shape: torch.Size([160])\n",
      "Parameter: layers.2.blocks.3.local_conv.bn.bias, Shape: torch.Size([160])\n",
      "Parameter: layers.2.blocks.3.local_conv.bn.running_mean, Shape: torch.Size([160])\n",
      "Parameter: layers.2.blocks.3.local_conv.bn.running_var, Shape: torch.Size([160])\n",
      "Parameter: layers.2.blocks.3.local_conv.bn.num_batches_tracked, Shape: torch.Size([])\n",
      "Parameter: layers.2.blocks.4.attn.attention_biases, Shape: torch.Size([5, 196])\n",
      "Parameter: layers.2.blocks.4.attn.norm.weight, Shape: torch.Size([160])\n",
      "Parameter: layers.2.blocks.4.attn.norm.bias, Shape: torch.Size([160])\n",
      "Parameter: layers.2.blocks.4.attn.qkv.weight, Shape: torch.Size([480, 160])\n",
      "Parameter: layers.2.blocks.4.attn.qkv.bias, Shape: torch.Size([480])\n",
      "Parameter: layers.2.blocks.4.attn.proj.weight, Shape: torch.Size([160, 160])\n",
      "Parameter: layers.2.blocks.4.attn.proj.bias, Shape: torch.Size([160])\n",
      "Parameter: layers.2.blocks.4.mlp.norm.weight, Shape: torch.Size([160])\n",
      "Parameter: layers.2.blocks.4.mlp.norm.bias, Shape: torch.Size([160])\n",
      "Parameter: layers.2.blocks.4.mlp.fc1.weight, Shape: torch.Size([640, 160])\n",
      "Parameter: layers.2.blocks.4.mlp.fc1.bias, Shape: torch.Size([640])\n",
      "Parameter: layers.2.blocks.4.mlp.fc2.weight, Shape: torch.Size([160, 640])\n",
      "Parameter: layers.2.blocks.4.mlp.fc2.bias, Shape: torch.Size([160])\n",
      "Parameter: layers.2.blocks.4.local_conv.c.weight, Shape: torch.Size([160, 1, 3, 3])\n",
      "Parameter: layers.2.blocks.4.local_conv.bn.weight, Shape: torch.Size([160])\n",
      "Parameter: layers.2.blocks.4.local_conv.bn.bias, Shape: torch.Size([160])\n",
      "Parameter: layers.2.blocks.4.local_conv.bn.running_mean, Shape: torch.Size([160])\n",
      "Parameter: layers.2.blocks.4.local_conv.bn.running_var, Shape: torch.Size([160])\n",
      "Parameter: layers.2.blocks.4.local_conv.bn.num_batches_tracked, Shape: torch.Size([])\n",
      "Parameter: layers.2.blocks.5.attn.attention_biases, Shape: torch.Size([5, 196])\n",
      "Parameter: layers.2.blocks.5.attn.norm.weight, Shape: torch.Size([160])\n",
      "Parameter: layers.2.blocks.5.attn.norm.bias, Shape: torch.Size([160])\n",
      "Parameter: layers.2.blocks.5.attn.qkv.weight, Shape: torch.Size([480, 160])\n",
      "Parameter: layers.2.blocks.5.attn.qkv.bias, Shape: torch.Size([480])\n",
      "Parameter: layers.2.blocks.5.attn.proj.weight, Shape: torch.Size([160, 160])\n",
      "Parameter: layers.2.blocks.5.attn.proj.bias, Shape: torch.Size([160])\n",
      "Parameter: layers.2.blocks.5.mlp.norm.weight, Shape: torch.Size([160])\n",
      "Parameter: layers.2.blocks.5.mlp.norm.bias, Shape: torch.Size([160])\n",
      "Parameter: layers.2.blocks.5.mlp.fc1.weight, Shape: torch.Size([640, 160])\n",
      "Parameter: layers.2.blocks.5.mlp.fc1.bias, Shape: torch.Size([640])\n",
      "Parameter: layers.2.blocks.5.mlp.fc2.weight, Shape: torch.Size([160, 640])\n",
      "Parameter: layers.2.blocks.5.mlp.fc2.bias, Shape: torch.Size([160])\n",
      "Parameter: layers.2.blocks.5.local_conv.c.weight, Shape: torch.Size([160, 1, 3, 3])\n",
      "Parameter: layers.2.blocks.5.local_conv.bn.weight, Shape: torch.Size([160])\n",
      "Parameter: layers.2.blocks.5.local_conv.bn.bias, Shape: torch.Size([160])\n",
      "Parameter: layers.2.blocks.5.local_conv.bn.running_mean, Shape: torch.Size([160])\n",
      "Parameter: layers.2.blocks.5.local_conv.bn.running_var, Shape: torch.Size([160])\n",
      "Parameter: layers.2.blocks.5.local_conv.bn.num_batches_tracked, Shape: torch.Size([])\n",
      "Parameter: layers.2.downsample.conv1.c.weight, Shape: torch.Size([320, 160, 1, 1])\n",
      "Parameter: layers.2.downsample.conv1.bn.weight, Shape: torch.Size([320])\n",
      "Parameter: layers.2.downsample.conv1.bn.bias, Shape: torch.Size([320])\n",
      "Parameter: layers.2.downsample.conv1.bn.running_mean, Shape: torch.Size([320])\n",
      "Parameter: layers.2.downsample.conv1.bn.running_var, Shape: torch.Size([320])\n",
      "Parameter: layers.2.downsample.conv1.bn.num_batches_tracked, Shape: torch.Size([])\n",
      "Parameter: layers.2.downsample.conv2.c.weight, Shape: torch.Size([320, 1, 3, 3])\n",
      "Parameter: layers.2.downsample.conv2.bn.weight, Shape: torch.Size([320])\n",
      "Parameter: layers.2.downsample.conv2.bn.bias, Shape: torch.Size([320])\n",
      "Parameter: layers.2.downsample.conv2.bn.running_mean, Shape: torch.Size([320])\n",
      "Parameter: layers.2.downsample.conv2.bn.running_var, Shape: torch.Size([320])\n",
      "Parameter: layers.2.downsample.conv2.bn.num_batches_tracked, Shape: torch.Size([])\n",
      "Parameter: layers.2.downsample.conv3.c.weight, Shape: torch.Size([320, 320, 1, 1])\n",
      "Parameter: layers.2.downsample.conv3.bn.weight, Shape: torch.Size([320])\n",
      "Parameter: layers.2.downsample.conv3.bn.bias, Shape: torch.Size([320])\n",
      "Parameter: layers.2.downsample.conv3.bn.running_mean, Shape: torch.Size([320])\n",
      "Parameter: layers.2.downsample.conv3.bn.running_var, Shape: torch.Size([320])\n",
      "Parameter: layers.2.downsample.conv3.bn.num_batches_tracked, Shape: torch.Size([])\n",
      "Parameter: layers.3.blocks.0.attn.attention_biases, Shape: torch.Size([10, 49])\n",
      "Parameter: layers.3.blocks.0.attn.norm.weight, Shape: torch.Size([320])\n",
      "Parameter: layers.3.blocks.0.attn.norm.bias, Shape: torch.Size([320])\n",
      "Parameter: layers.3.blocks.0.attn.qkv.weight, Shape: torch.Size([960, 320])\n",
      "Parameter: layers.3.blocks.0.attn.qkv.bias, Shape: torch.Size([960])\n",
      "Parameter: layers.3.blocks.0.attn.proj.weight, Shape: torch.Size([320, 320])\n",
      "Parameter: layers.3.blocks.0.attn.proj.bias, Shape: torch.Size([320])\n",
      "Parameter: layers.3.blocks.0.mlp.norm.weight, Shape: torch.Size([320])\n",
      "Parameter: layers.3.blocks.0.mlp.norm.bias, Shape: torch.Size([320])\n",
      "Parameter: layers.3.blocks.0.mlp.fc1.weight, Shape: torch.Size([1280, 320])\n",
      "Parameter: layers.3.blocks.0.mlp.fc1.bias, Shape: torch.Size([1280])\n",
      "Parameter: layers.3.blocks.0.mlp.fc2.weight, Shape: torch.Size([320, 1280])\n",
      "Parameter: layers.3.blocks.0.mlp.fc2.bias, Shape: torch.Size([320])\n",
      "Parameter: layers.3.blocks.0.local_conv.c.weight, Shape: torch.Size([320, 1, 3, 3])\n",
      "Parameter: layers.3.blocks.0.local_conv.bn.weight, Shape: torch.Size([320])\n",
      "Parameter: layers.3.blocks.0.local_conv.bn.bias, Shape: torch.Size([320])\n",
      "Parameter: layers.3.blocks.0.local_conv.bn.running_mean, Shape: torch.Size([320])\n",
      "Parameter: layers.3.blocks.0.local_conv.bn.running_var, Shape: torch.Size([320])\n",
      "Parameter: layers.3.blocks.0.local_conv.bn.num_batches_tracked, Shape: torch.Size([])\n",
      "Parameter: layers.3.blocks.1.attn.attention_biases, Shape: torch.Size([10, 49])\n",
      "Parameter: layers.3.blocks.1.attn.norm.weight, Shape: torch.Size([320])\n",
      "Parameter: layers.3.blocks.1.attn.norm.bias, Shape: torch.Size([320])\n",
      "Parameter: layers.3.blocks.1.attn.qkv.weight, Shape: torch.Size([960, 320])\n",
      "Parameter: layers.3.blocks.1.attn.qkv.bias, Shape: torch.Size([960])\n",
      "Parameter: layers.3.blocks.1.attn.proj.weight, Shape: torch.Size([320, 320])\n",
      "Parameter: layers.3.blocks.1.attn.proj.bias, Shape: torch.Size([320])\n",
      "Parameter: layers.3.blocks.1.mlp.norm.weight, Shape: torch.Size([320])\n",
      "Parameter: layers.3.blocks.1.mlp.norm.bias, Shape: torch.Size([320])\n",
      "Parameter: layers.3.blocks.1.mlp.fc1.weight, Shape: torch.Size([1280, 320])\n",
      "Parameter: layers.3.blocks.1.mlp.fc1.bias, Shape: torch.Size([1280])\n",
      "Parameter: layers.3.blocks.1.mlp.fc2.weight, Shape: torch.Size([320, 1280])\n",
      "Parameter: layers.3.blocks.1.mlp.fc2.bias, Shape: torch.Size([320])\n",
      "Parameter: layers.3.blocks.1.local_conv.c.weight, Shape: torch.Size([320, 1, 3, 3])\n",
      "Parameter: layers.3.blocks.1.local_conv.bn.weight, Shape: torch.Size([320])\n",
      "Parameter: layers.3.blocks.1.local_conv.bn.bias, Shape: torch.Size([320])\n",
      "Parameter: layers.3.blocks.1.local_conv.bn.running_mean, Shape: torch.Size([320])\n",
      "Parameter: layers.3.blocks.1.local_conv.bn.running_var, Shape: torch.Size([320])\n",
      "Parameter: layers.3.blocks.1.local_conv.bn.num_batches_tracked, Shape: torch.Size([])\n",
      "Parameter: neck.0.weight, Shape: torch.Size([256, 320, 1, 1])\n",
      "Parameter: neck.1.weight, Shape: torch.Size([256])\n",
      "Parameter: neck.1.bias, Shape: torch.Size([256])\n",
      "Parameter: neck.2.weight, Shape: torch.Size([256, 256, 3, 3])\n",
      "Parameter: neck.3.weight, Shape: torch.Size([256])\n",
      "Parameter: neck.3.bias, Shape: torch.Size([256])\n",
      "Parameter: patch_embed.seq.0.c.weight, Value: tensor([[[[-0.3083]],\n",
      "\n",
      "         [[ 0.1444]],\n",
      "\n",
      "         [[ 0.1258]]],\n",
      "\n",
      "\n",
      "        [[[-0.0848]],\n",
      "\n",
      "         [[-0.3785]],\n",
      "\n",
      "         [[ 0.2477]]],\n",
      "\n",
      "\n",
      "        [[[-0.2842]],\n",
      "\n",
      "         [[ 0.5611]],\n",
      "\n",
      "         [[-0.3164]]],\n",
      "\n",
      "\n",
      "        [[[ 0.3291]],\n",
      "\n",
      "         [[ 0.0266]],\n",
      "\n",
      "         [[ 0.2963]]],\n",
      "\n",
      "\n",
      "        [[[ 0.3553]],\n",
      "\n",
      "         [[ 0.5620]],\n",
      "\n",
      "         [[-0.5016]]],\n",
      "\n",
      "\n",
      "        [[[ 0.1965]],\n",
      "\n",
      "         [[-0.3488]],\n",
      "\n",
      "         [[-0.5351]]],\n",
      "\n",
      "\n",
      "        [[[ 0.3396]],\n",
      "\n",
      "         [[ 0.2324]],\n",
      "\n",
      "         [[-0.4222]]],\n",
      "\n",
      "\n",
      "        [[[-0.5149]],\n",
      "\n",
      "         [[-0.3672]],\n",
      "\n",
      "         [[-0.1460]]],\n",
      "\n",
      "\n",
      "        [[[-0.1537]],\n",
      "\n",
      "         [[ 0.5120]],\n",
      "\n",
      "         [[ 0.3793]]],\n",
      "\n",
      "\n",
      "        [[[-0.5654]],\n",
      "\n",
      "         [[-0.1461]],\n",
      "\n",
      "         [[-0.2641]]],\n",
      "\n",
      "\n",
      "        [[[ 0.5447]],\n",
      "\n",
      "         [[ 0.2484]],\n",
      "\n",
      "         [[ 0.0269]]],\n",
      "\n",
      "\n",
      "        [[[-0.4845]],\n",
      "\n",
      "         [[-0.1067]],\n",
      "\n",
      "         [[-0.3547]]],\n",
      "\n",
      "\n",
      "        [[[-0.1426]],\n",
      "\n",
      "         [[ 0.3706]],\n",
      "\n",
      "         [[ 0.3992]]],\n",
      "\n",
      "\n",
      "        [[[-0.3378]],\n",
      "\n",
      "         [[ 0.5571]],\n",
      "\n",
      "         [[-0.3780]]],\n",
      "\n",
      "\n",
      "        [[[-0.0500]],\n",
      "\n",
      "         [[-0.1036]],\n",
      "\n",
      "         [[-0.0207]]],\n",
      "\n",
      "\n",
      "        [[[-0.1783]],\n",
      "\n",
      "         [[ 0.1878]],\n",
      "\n",
      "         [[-0.4980]]],\n",
      "\n",
      "\n",
      "        [[[ 0.0083]],\n",
      "\n",
      "         [[-0.4546]],\n",
      "\n",
      "         [[ 0.2202]]],\n",
      "\n",
      "\n",
      "        [[[-0.5487]],\n",
      "\n",
      "         [[ 0.2809]],\n",
      "\n",
      "         [[ 0.2298]]],\n",
      "\n",
      "\n",
      "        [[[-0.2655]],\n",
      "\n",
      "         [[ 0.5308]],\n",
      "\n",
      "         [[ 0.0396]]],\n",
      "\n",
      "\n",
      "        [[[ 0.3081]],\n",
      "\n",
      "         [[-0.3828]],\n",
      "\n",
      "         [[ 0.4795]]],\n",
      "\n",
      "\n",
      "        [[[-0.0894]],\n",
      "\n",
      "         [[ 0.4915]],\n",
      "\n",
      "         [[ 0.3511]]],\n",
      "\n",
      "\n",
      "        [[[ 0.4304]],\n",
      "\n",
      "         [[ 0.2538]],\n",
      "\n",
      "         [[ 0.3621]]],\n",
      "\n",
      "\n",
      "        [[[-0.2756]],\n",
      "\n",
      "         [[-0.1992]],\n",
      "\n",
      "         [[ 0.5047]]],\n",
      "\n",
      "\n",
      "        [[[-0.5332]],\n",
      "\n",
      "         [[-0.3026]],\n",
      "\n",
      "         [[-0.0502]]],\n",
      "\n",
      "\n",
      "        [[[-0.3214]],\n",
      "\n",
      "         [[-0.3150]],\n",
      "\n",
      "         [[ 0.4694]]],\n",
      "\n",
      "\n",
      "        [[[ 0.5414]],\n",
      "\n",
      "         [[ 0.4729]],\n",
      "\n",
      "         [[-0.5110]]],\n",
      "\n",
      "\n",
      "        [[[ 0.0131]],\n",
      "\n",
      "         [[-0.0481]],\n",
      "\n",
      "         [[ 0.5317]]],\n",
      "\n",
      "\n",
      "        [[[ 0.3265]],\n",
      "\n",
      "         [[ 0.0024]],\n",
      "\n",
      "         [[ 0.0349]]],\n",
      "\n",
      "\n",
      "        [[[ 0.1669]],\n",
      "\n",
      "         [[-0.2653]],\n",
      "\n",
      "         [[-0.2951]]],\n",
      "\n",
      "\n",
      "        [[[ 0.5665]],\n",
      "\n",
      "         [[-0.1267]],\n",
      "\n",
      "         [[ 0.4632]]],\n",
      "\n",
      "\n",
      "        [[[-0.0951]],\n",
      "\n",
      "         [[-0.0057]],\n",
      "\n",
      "         [[ 0.4496]]],\n",
      "\n",
      "\n",
      "        [[[ 0.4932]],\n",
      "\n",
      "         [[-0.1215]],\n",
      "\n",
      "         [[ 0.5027]]]])\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "\n",
    "checkpoint_path = '/mnt/sda/minkyukim/pth/tiny-brats-distill/tiny_model_best.pth'\n",
    "\n",
    "checkpoint = torch.load(checkpoint_path, map_location=torch.device('cpu'))\n",
    "\n",
    "for name, param in checkpoint.items():\n",
    "    print(f\"Parameter: {name}, Shape: {param.shape}\")\n",
    "\n",
    "\n",
    "param_name = list(checkpoint.keys())[0]\n",
    "param_value = checkpoint[param_name]\n",
    "print(f\"Parameter: {param_name}, Value: {param_value}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Parameter: image_encoder.patch_embed.seq.0.c.weight - Different\n",
      "Parameter: image_encoder.patch_embed.seq.0.bn.weight - Different\n",
      "Parameter: image_encoder.patch_embed.seq.0.bn.bias - Different\n",
      "Parameter: image_encoder.patch_embed.seq.0.bn.running_mean - Different\n",
      "Parameter: image_encoder.patch_embed.seq.0.bn.running_var - Different\n",
      "Parameter: image_encoder.patch_embed.seq.0.bn.num_batches_tracked - Different\n",
      "Parameter: image_encoder.patch_embed.seq.2.c.weight - Different\n",
      "Parameter: image_encoder.patch_embed.seq.2.bn.weight - Different\n",
      "Parameter: image_encoder.patch_embed.seq.2.bn.bias - Different\n",
      "Parameter: image_encoder.patch_embed.seq.2.bn.running_mean - Different\n",
      "Parameter: image_encoder.patch_embed.seq.2.bn.running_var - Different\n",
      "Parameter: image_encoder.patch_embed.seq.2.bn.num_batches_tracked - Different\n",
      "Parameter: image_encoder.layers.0.blocks.0.conv1.c.weight - Different\n",
      "Parameter: image_encoder.layers.0.blocks.0.conv1.bn.weight - Different\n",
      "Parameter: image_encoder.layers.0.blocks.0.conv1.bn.bias - Different\n",
      "Parameter: image_encoder.layers.0.blocks.0.conv1.bn.running_mean - Different\n",
      "Parameter: image_encoder.layers.0.blocks.0.conv1.bn.running_var - Different\n",
      "Parameter: image_encoder.layers.0.blocks.0.conv1.bn.num_batches_tracked - Different\n",
      "Parameter: image_encoder.layers.0.blocks.0.conv2.c.weight - Different\n",
      "Parameter: image_encoder.layers.0.blocks.0.conv2.bn.weight - Different\n",
      "Parameter: image_encoder.layers.0.blocks.0.conv2.bn.bias - Different\n",
      "Parameter: image_encoder.layers.0.blocks.0.conv2.bn.running_mean - Different\n",
      "Parameter: image_encoder.layers.0.blocks.0.conv2.bn.running_var - Different\n",
      "Parameter: image_encoder.layers.0.blocks.0.conv2.bn.num_batches_tracked - Different\n",
      "Parameter: image_encoder.layers.0.blocks.0.conv3.c.weight - Different\n",
      "Parameter: image_encoder.layers.0.blocks.0.conv3.bn.weight - Different\n",
      "Parameter: image_encoder.layers.0.blocks.0.conv3.bn.bias - Different\n",
      "Parameter: image_encoder.layers.0.blocks.0.conv3.bn.running_mean - Different\n",
      "Parameter: image_encoder.layers.0.blocks.0.conv3.bn.running_var - Different\n",
      "Parameter: image_encoder.layers.0.blocks.0.conv3.bn.num_batches_tracked - Different\n",
      "Parameter: image_encoder.layers.0.blocks.1.conv1.c.weight - Different\n",
      "Parameter: image_encoder.layers.0.blocks.1.conv1.bn.weight - Different\n",
      "Parameter: image_encoder.layers.0.blocks.1.conv1.bn.bias - Different\n",
      "Parameter: image_encoder.layers.0.blocks.1.conv1.bn.running_mean - Different\n",
      "Parameter: image_encoder.layers.0.blocks.1.conv1.bn.running_var - Different\n",
      "Parameter: image_encoder.layers.0.blocks.1.conv1.bn.num_batches_tracked - Different\n",
      "Parameter: image_encoder.layers.0.blocks.1.conv2.c.weight - Different\n",
      "Parameter: image_encoder.layers.0.blocks.1.conv2.bn.weight - Different\n",
      "Parameter: image_encoder.layers.0.blocks.1.conv2.bn.bias - Different\n",
      "Parameter: image_encoder.layers.0.blocks.1.conv2.bn.running_mean - Different\n",
      "Parameter: image_encoder.layers.0.blocks.1.conv2.bn.running_var - Different\n",
      "Parameter: image_encoder.layers.0.blocks.1.conv2.bn.num_batches_tracked - Different\n",
      "Parameter: image_encoder.layers.0.blocks.1.conv3.c.weight - Different\n",
      "Parameter: image_encoder.layers.0.blocks.1.conv3.bn.weight - Different\n",
      "Parameter: image_encoder.layers.0.blocks.1.conv3.bn.bias - Different\n",
      "Parameter: image_encoder.layers.0.blocks.1.conv3.bn.running_mean - Different\n",
      "Parameter: image_encoder.layers.0.blocks.1.conv3.bn.running_var - Different\n",
      "Parameter: image_encoder.layers.0.blocks.1.conv3.bn.num_batches_tracked - Different\n",
      "Parameter: image_encoder.layers.0.downsample.conv1.c.weight - Different\n",
      "Parameter: image_encoder.layers.0.downsample.conv1.bn.weight - Different\n",
      "Parameter: image_encoder.layers.0.downsample.conv1.bn.bias - Different\n",
      "Parameter: image_encoder.layers.0.downsample.conv1.bn.running_mean - Different\n",
      "Parameter: image_encoder.layers.0.downsample.conv1.bn.running_var - Different\n",
      "Parameter: image_encoder.layers.0.downsample.conv1.bn.num_batches_tracked - Different\n",
      "Parameter: image_encoder.layers.0.downsample.conv2.c.weight - Different\n",
      "Parameter: image_encoder.layers.0.downsample.conv2.bn.weight - Different\n",
      "Parameter: image_encoder.layers.0.downsample.conv2.bn.bias - Different\n",
      "Parameter: image_encoder.layers.0.downsample.conv2.bn.running_mean - Different\n",
      "Parameter: image_encoder.layers.0.downsample.conv2.bn.running_var - Different\n",
      "Parameter: image_encoder.layers.0.downsample.conv2.bn.num_batches_tracked - Different\n",
      "Parameter: image_encoder.layers.0.downsample.conv3.c.weight - Different\n",
      "Parameter: image_encoder.layers.0.downsample.conv3.bn.weight - Different\n",
      "Parameter: image_encoder.layers.0.downsample.conv3.bn.bias - Different\n",
      "Parameter: image_encoder.layers.0.downsample.conv3.bn.running_mean - Different\n",
      "Parameter: image_encoder.layers.0.downsample.conv3.bn.running_var - Different\n",
      "Parameter: image_encoder.layers.0.downsample.conv3.bn.num_batches_tracked - Different\n",
      "Parameter: image_encoder.layers.1.blocks.0.attn.attention_biases - Different\n",
      "Parameter: image_encoder.layers.1.blocks.0.attn.norm.weight - Different\n",
      "Parameter: image_encoder.layers.1.blocks.0.attn.norm.bias - Different\n",
      "Parameter: image_encoder.layers.1.blocks.0.attn.qkv.weight - Different\n",
      "Parameter: image_encoder.layers.1.blocks.0.attn.qkv.bias - Different\n",
      "Parameter: image_encoder.layers.1.blocks.0.attn.proj.weight - Different\n",
      "Parameter: image_encoder.layers.1.blocks.0.attn.proj.bias - Different\n",
      "Parameter: image_encoder.layers.1.blocks.0.mlp.norm.weight - Different\n",
      "Parameter: image_encoder.layers.1.blocks.0.mlp.norm.bias - Different\n",
      "Parameter: image_encoder.layers.1.blocks.0.mlp.fc1.weight - Different\n",
      "Parameter: image_encoder.layers.1.blocks.0.mlp.fc1.bias - Different\n",
      "Parameter: image_encoder.layers.1.blocks.0.mlp.fc2.weight - Different\n",
      "Parameter: image_encoder.layers.1.blocks.0.mlp.fc2.bias - Different\n",
      "Parameter: image_encoder.layers.1.blocks.0.local_conv.c.weight - Different\n",
      "Parameter: image_encoder.layers.1.blocks.0.local_conv.bn.weight - Different\n",
      "Parameter: image_encoder.layers.1.blocks.0.local_conv.bn.bias - Different\n",
      "Parameter: image_encoder.layers.1.blocks.0.local_conv.bn.running_mean - Different\n",
      "Parameter: image_encoder.layers.1.blocks.0.local_conv.bn.running_var - Different\n",
      "Parameter: image_encoder.layers.1.blocks.0.local_conv.bn.num_batches_tracked - Different\n",
      "Parameter: image_encoder.layers.1.blocks.1.attn.attention_biases - Different\n",
      "Parameter: image_encoder.layers.1.blocks.1.attn.norm.weight - Different\n",
      "Parameter: image_encoder.layers.1.blocks.1.attn.norm.bias - Different\n",
      "Parameter: image_encoder.layers.1.blocks.1.attn.qkv.weight - Different\n",
      "Parameter: image_encoder.layers.1.blocks.1.attn.qkv.bias - Different\n",
      "Parameter: image_encoder.layers.1.blocks.1.attn.proj.weight - Different\n",
      "Parameter: image_encoder.layers.1.blocks.1.attn.proj.bias - Different\n",
      "Parameter: image_encoder.layers.1.blocks.1.mlp.norm.weight - Different\n",
      "Parameter: image_encoder.layers.1.blocks.1.mlp.norm.bias - Different\n",
      "Parameter: image_encoder.layers.1.blocks.1.mlp.fc1.weight - Different\n",
      "Parameter: image_encoder.layers.1.blocks.1.mlp.fc1.bias - Different\n",
      "Parameter: image_encoder.layers.1.blocks.1.mlp.fc2.weight - Different\n",
      "Parameter: image_encoder.layers.1.blocks.1.mlp.fc2.bias - Different\n",
      "Parameter: image_encoder.layers.1.blocks.1.local_conv.c.weight - Different\n",
      "Parameter: image_encoder.layers.1.blocks.1.local_conv.bn.weight - Different\n",
      "Parameter: image_encoder.layers.1.blocks.1.local_conv.bn.bias - Different\n",
      "Parameter: image_encoder.layers.1.blocks.1.local_conv.bn.running_mean - Different\n",
      "Parameter: image_encoder.layers.1.blocks.1.local_conv.bn.running_var - Different\n",
      "Parameter: image_encoder.layers.1.blocks.1.local_conv.bn.num_batches_tracked - Different\n",
      "Parameter: image_encoder.layers.1.downsample.conv1.c.weight - Different\n",
      "Parameter: image_encoder.layers.1.downsample.conv1.bn.weight - Different\n",
      "Parameter: image_encoder.layers.1.downsample.conv1.bn.bias - Different\n",
      "Parameter: image_encoder.layers.1.downsample.conv1.bn.running_mean - Different\n",
      "Parameter: image_encoder.layers.1.downsample.conv1.bn.running_var - Different\n",
      "Parameter: image_encoder.layers.1.downsample.conv1.bn.num_batches_tracked - Different\n",
      "Parameter: image_encoder.layers.1.downsample.conv2.c.weight - Different\n",
      "Parameter: image_encoder.layers.1.downsample.conv2.bn.weight - Different\n",
      "Parameter: image_encoder.layers.1.downsample.conv2.bn.bias - Different\n",
      "Parameter: image_encoder.layers.1.downsample.conv2.bn.running_mean - Different\n",
      "Parameter: image_encoder.layers.1.downsample.conv2.bn.running_var - Different\n",
      "Parameter: image_encoder.layers.1.downsample.conv2.bn.num_batches_tracked - Different\n",
      "Parameter: image_encoder.layers.1.downsample.conv3.c.weight - Different\n",
      "Parameter: image_encoder.layers.1.downsample.conv3.bn.weight - Different\n",
      "Parameter: image_encoder.layers.1.downsample.conv3.bn.bias - Different\n",
      "Parameter: image_encoder.layers.1.downsample.conv3.bn.running_mean - Different\n",
      "Parameter: image_encoder.layers.1.downsample.conv3.bn.running_var - Different\n",
      "Parameter: image_encoder.layers.1.downsample.conv3.bn.num_batches_tracked - Different\n",
      "Parameter: image_encoder.layers.2.blocks.0.attn.attention_biases - Different\n",
      "Parameter: image_encoder.layers.2.blocks.0.attn.norm.weight - Different\n",
      "Parameter: image_encoder.layers.2.blocks.0.attn.norm.bias - Different\n",
      "Parameter: image_encoder.layers.2.blocks.0.attn.qkv.weight - Different\n",
      "Parameter: image_encoder.layers.2.blocks.0.attn.qkv.bias - Different\n",
      "Parameter: image_encoder.layers.2.blocks.0.attn.proj.weight - Different\n",
      "Parameter: image_encoder.layers.2.blocks.0.attn.proj.bias - Different\n",
      "Parameter: image_encoder.layers.2.blocks.0.mlp.norm.weight - Different\n",
      "Parameter: image_encoder.layers.2.blocks.0.mlp.norm.bias - Different\n",
      "Parameter: image_encoder.layers.2.blocks.0.mlp.fc1.weight - Different\n",
      "Parameter: image_encoder.layers.2.blocks.0.mlp.fc1.bias - Different\n",
      "Parameter: image_encoder.layers.2.blocks.0.mlp.fc2.weight - Different\n",
      "Parameter: image_encoder.layers.2.blocks.0.mlp.fc2.bias - Different\n",
      "Parameter: image_encoder.layers.2.blocks.0.local_conv.c.weight - Different\n",
      "Parameter: image_encoder.layers.2.blocks.0.local_conv.bn.weight - Different\n",
      "Parameter: image_encoder.layers.2.blocks.0.local_conv.bn.bias - Different\n",
      "Parameter: image_encoder.layers.2.blocks.0.local_conv.bn.running_mean - Different\n",
      "Parameter: image_encoder.layers.2.blocks.0.local_conv.bn.running_var - Different\n",
      "Parameter: image_encoder.layers.2.blocks.0.local_conv.bn.num_batches_tracked - Different\n",
      "Parameter: image_encoder.layers.2.blocks.1.attn.attention_biases - Different\n",
      "Parameter: image_encoder.layers.2.blocks.1.attn.norm.weight - Different\n",
      "Parameter: image_encoder.layers.2.blocks.1.attn.norm.bias - Different\n",
      "Parameter: image_encoder.layers.2.blocks.1.attn.qkv.weight - Different\n",
      "Parameter: image_encoder.layers.2.blocks.1.attn.qkv.bias - Different\n",
      "Parameter: image_encoder.layers.2.blocks.1.attn.proj.weight - Different\n",
      "Parameter: image_encoder.layers.2.blocks.1.attn.proj.bias - Different\n",
      "Parameter: image_encoder.layers.2.blocks.1.mlp.norm.weight - Different\n",
      "Parameter: image_encoder.layers.2.blocks.1.mlp.norm.bias - Different\n",
      "Parameter: image_encoder.layers.2.blocks.1.mlp.fc1.weight - Different\n",
      "Parameter: image_encoder.layers.2.blocks.1.mlp.fc1.bias - Different\n",
      "Parameter: image_encoder.layers.2.blocks.1.mlp.fc2.weight - Different\n",
      "Parameter: image_encoder.layers.2.blocks.1.mlp.fc2.bias - Different\n",
      "Parameter: image_encoder.layers.2.blocks.1.local_conv.c.weight - Different\n",
      "Parameter: image_encoder.layers.2.blocks.1.local_conv.bn.weight - Different\n",
      "Parameter: image_encoder.layers.2.blocks.1.local_conv.bn.bias - Different\n",
      "Parameter: image_encoder.layers.2.blocks.1.local_conv.bn.running_mean - Different\n",
      "Parameter: image_encoder.layers.2.blocks.1.local_conv.bn.running_var - Different\n",
      "Parameter: image_encoder.layers.2.blocks.1.local_conv.bn.num_batches_tracked - Different\n",
      "Parameter: image_encoder.layers.2.blocks.2.attn.attention_biases - Different\n",
      "Parameter: image_encoder.layers.2.blocks.2.attn.norm.weight - Different\n",
      "Parameter: image_encoder.layers.2.blocks.2.attn.norm.bias - Different\n",
      "Parameter: image_encoder.layers.2.blocks.2.attn.qkv.weight - Different\n",
      "Parameter: image_encoder.layers.2.blocks.2.attn.qkv.bias - Different\n",
      "Parameter: image_encoder.layers.2.blocks.2.attn.proj.weight - Different\n",
      "Parameter: image_encoder.layers.2.blocks.2.attn.proj.bias - Different\n",
      "Parameter: image_encoder.layers.2.blocks.2.mlp.norm.weight - Different\n",
      "Parameter: image_encoder.layers.2.blocks.2.mlp.norm.bias - Different\n",
      "Parameter: image_encoder.layers.2.blocks.2.mlp.fc1.weight - Different\n",
      "Parameter: image_encoder.layers.2.blocks.2.mlp.fc1.bias - Different\n",
      "Parameter: image_encoder.layers.2.blocks.2.mlp.fc2.weight - Different\n",
      "Parameter: image_encoder.layers.2.blocks.2.mlp.fc2.bias - Different\n",
      "Parameter: image_encoder.layers.2.blocks.2.local_conv.c.weight - Different\n",
      "Parameter: image_encoder.layers.2.blocks.2.local_conv.bn.weight - Different\n",
      "Parameter: image_encoder.layers.2.blocks.2.local_conv.bn.bias - Different\n",
      "Parameter: image_encoder.layers.2.blocks.2.local_conv.bn.running_mean - Different\n",
      "Parameter: image_encoder.layers.2.blocks.2.local_conv.bn.running_var - Different\n",
      "Parameter: image_encoder.layers.2.blocks.2.local_conv.bn.num_batches_tracked - Different\n",
      "Parameter: image_encoder.layers.2.blocks.3.attn.attention_biases - Different\n",
      "Parameter: image_encoder.layers.2.blocks.3.attn.norm.weight - Different\n",
      "Parameter: image_encoder.layers.2.blocks.3.attn.norm.bias - Different\n",
      "Parameter: image_encoder.layers.2.blocks.3.attn.qkv.weight - Different\n",
      "Parameter: image_encoder.layers.2.blocks.3.attn.qkv.bias - Different\n",
      "Parameter: image_encoder.layers.2.blocks.3.attn.proj.weight - Different\n",
      "Parameter: image_encoder.layers.2.blocks.3.attn.proj.bias - Different\n",
      "Parameter: image_encoder.layers.2.blocks.3.mlp.norm.weight - Different\n",
      "Parameter: image_encoder.layers.2.blocks.3.mlp.norm.bias - Different\n",
      "Parameter: image_encoder.layers.2.blocks.3.mlp.fc1.weight - Different\n",
      "Parameter: image_encoder.layers.2.blocks.3.mlp.fc1.bias - Different\n",
      "Parameter: image_encoder.layers.2.blocks.3.mlp.fc2.weight - Different\n",
      "Parameter: image_encoder.layers.2.blocks.3.mlp.fc2.bias - Different\n",
      "Parameter: image_encoder.layers.2.blocks.3.local_conv.c.weight - Different\n",
      "Parameter: image_encoder.layers.2.blocks.3.local_conv.bn.weight - Different\n",
      "Parameter: image_encoder.layers.2.blocks.3.local_conv.bn.bias - Different\n",
      "Parameter: image_encoder.layers.2.blocks.3.local_conv.bn.running_mean - Different\n",
      "Parameter: image_encoder.layers.2.blocks.3.local_conv.bn.running_var - Different\n",
      "Parameter: image_encoder.layers.2.blocks.3.local_conv.bn.num_batches_tracked - Different\n",
      "Parameter: image_encoder.layers.2.blocks.4.attn.attention_biases - Different\n",
      "Parameter: image_encoder.layers.2.blocks.4.attn.norm.weight - Different\n",
      "Parameter: image_encoder.layers.2.blocks.4.attn.norm.bias - Different\n",
      "Parameter: image_encoder.layers.2.blocks.4.attn.qkv.weight - Different\n",
      "Parameter: image_encoder.layers.2.blocks.4.attn.qkv.bias - Different\n",
      "Parameter: image_encoder.layers.2.blocks.4.attn.proj.weight - Different\n",
      "Parameter: image_encoder.layers.2.blocks.4.attn.proj.bias - Different\n",
      "Parameter: image_encoder.layers.2.blocks.4.mlp.norm.weight - Different\n",
      "Parameter: image_encoder.layers.2.blocks.4.mlp.norm.bias - Different\n",
      "Parameter: image_encoder.layers.2.blocks.4.mlp.fc1.weight - Different\n",
      "Parameter: image_encoder.layers.2.blocks.4.mlp.fc1.bias - Different\n",
      "Parameter: image_encoder.layers.2.blocks.4.mlp.fc2.weight - Different\n",
      "Parameter: image_encoder.layers.2.blocks.4.mlp.fc2.bias - Different\n",
      "Parameter: image_encoder.layers.2.blocks.4.local_conv.c.weight - Different\n",
      "Parameter: image_encoder.layers.2.blocks.4.local_conv.bn.weight - Different\n",
      "Parameter: image_encoder.layers.2.blocks.4.local_conv.bn.bias - Different\n",
      "Parameter: image_encoder.layers.2.blocks.4.local_conv.bn.running_mean - Different\n",
      "Parameter: image_encoder.layers.2.blocks.4.local_conv.bn.running_var - Different\n",
      "Parameter: image_encoder.layers.2.blocks.4.local_conv.bn.num_batches_tracked - Different\n",
      "Parameter: image_encoder.layers.2.blocks.5.attn.attention_biases - Different\n",
      "Parameter: image_encoder.layers.2.blocks.5.attn.norm.weight - Different\n",
      "Parameter: image_encoder.layers.2.blocks.5.attn.norm.bias - Different\n",
      "Parameter: image_encoder.layers.2.blocks.5.attn.qkv.weight - Different\n",
      "Parameter: image_encoder.layers.2.blocks.5.attn.qkv.bias - Different\n",
      "Parameter: image_encoder.layers.2.blocks.5.attn.proj.weight - Different\n",
      "Parameter: image_encoder.layers.2.blocks.5.attn.proj.bias - Different\n",
      "Parameter: image_encoder.layers.2.blocks.5.mlp.norm.weight - Different\n",
      "Parameter: image_encoder.layers.2.blocks.5.mlp.norm.bias - Different\n",
      "Parameter: image_encoder.layers.2.blocks.5.mlp.fc1.weight - Different\n",
      "Parameter: image_encoder.layers.2.blocks.5.mlp.fc1.bias - Different\n",
      "Parameter: image_encoder.layers.2.blocks.5.mlp.fc2.weight - Different\n",
      "Parameter: image_encoder.layers.2.blocks.5.mlp.fc2.bias - Different\n",
      "Parameter: image_encoder.layers.2.blocks.5.local_conv.c.weight - Different\n",
      "Parameter: image_encoder.layers.2.blocks.5.local_conv.bn.weight - Different\n",
      "Parameter: image_encoder.layers.2.blocks.5.local_conv.bn.bias - Different\n",
      "Parameter: image_encoder.layers.2.blocks.5.local_conv.bn.running_mean - Different\n",
      "Parameter: image_encoder.layers.2.blocks.5.local_conv.bn.running_var - Different\n",
      "Parameter: image_encoder.layers.2.blocks.5.local_conv.bn.num_batches_tracked - Different\n",
      "Parameter: image_encoder.layers.2.downsample.conv1.c.weight - Different\n",
      "Parameter: image_encoder.layers.2.downsample.conv1.bn.weight - Different\n",
      "Parameter: image_encoder.layers.2.downsample.conv1.bn.bias - Different\n",
      "Parameter: image_encoder.layers.2.downsample.conv1.bn.running_mean - Different\n",
      "Parameter: image_encoder.layers.2.downsample.conv1.bn.running_var - Different\n",
      "Parameter: image_encoder.layers.2.downsample.conv1.bn.num_batches_tracked - Different\n",
      "Parameter: image_encoder.layers.2.downsample.conv2.c.weight - Different\n",
      "Parameter: image_encoder.layers.2.downsample.conv2.bn.weight - Different\n",
      "Parameter: image_encoder.layers.2.downsample.conv2.bn.bias - Different\n",
      "Parameter: image_encoder.layers.2.downsample.conv2.bn.running_mean - Different\n",
      "Parameter: image_encoder.layers.2.downsample.conv2.bn.running_var - Different\n",
      "Parameter: image_encoder.layers.2.downsample.conv2.bn.num_batches_tracked - Different\n",
      "Parameter: image_encoder.layers.2.downsample.conv3.c.weight - Different\n",
      "Parameter: image_encoder.layers.2.downsample.conv3.bn.weight - Different\n",
      "Parameter: image_encoder.layers.2.downsample.conv3.bn.bias - Different\n",
      "Parameter: image_encoder.layers.2.downsample.conv3.bn.running_mean - Different\n",
      "Parameter: image_encoder.layers.2.downsample.conv3.bn.running_var - Different\n",
      "Parameter: image_encoder.layers.2.downsample.conv3.bn.num_batches_tracked - Different\n",
      "Parameter: image_encoder.layers.3.blocks.0.attn.attention_biases - Different\n",
      "Parameter: image_encoder.layers.3.blocks.0.attn.norm.weight - Different\n",
      "Parameter: image_encoder.layers.3.blocks.0.attn.norm.bias - Different\n",
      "Parameter: image_encoder.layers.3.blocks.0.attn.qkv.weight - Different\n",
      "Parameter: image_encoder.layers.3.blocks.0.attn.qkv.bias - Different\n",
      "Parameter: image_encoder.layers.3.blocks.0.attn.proj.weight - Different\n",
      "Parameter: image_encoder.layers.3.blocks.0.attn.proj.bias - Different\n",
      "Parameter: image_encoder.layers.3.blocks.0.mlp.norm.weight - Different\n",
      "Parameter: image_encoder.layers.3.blocks.0.mlp.norm.bias - Different\n",
      "Parameter: image_encoder.layers.3.blocks.0.mlp.fc1.weight - Different\n",
      "Parameter: image_encoder.layers.3.blocks.0.mlp.fc1.bias - Different\n",
      "Parameter: image_encoder.layers.3.blocks.0.mlp.fc2.weight - Different\n",
      "Parameter: image_encoder.layers.3.blocks.0.mlp.fc2.bias - Different\n",
      "Parameter: image_encoder.layers.3.blocks.0.local_conv.c.weight - Different\n",
      "Parameter: image_encoder.layers.3.blocks.0.local_conv.bn.weight - Different\n",
      "Parameter: image_encoder.layers.3.blocks.0.local_conv.bn.bias - Different\n",
      "Parameter: image_encoder.layers.3.blocks.0.local_conv.bn.running_mean - Different\n",
      "Parameter: image_encoder.layers.3.blocks.0.local_conv.bn.running_var - Different\n",
      "Parameter: image_encoder.layers.3.blocks.0.local_conv.bn.num_batches_tracked - Different\n",
      "Parameter: image_encoder.layers.3.blocks.1.attn.attention_biases - Different\n",
      "Parameter: image_encoder.layers.3.blocks.1.attn.norm.weight - Different\n",
      "Parameter: image_encoder.layers.3.blocks.1.attn.norm.bias - Different\n",
      "Parameter: image_encoder.layers.3.blocks.1.attn.qkv.weight - Different\n",
      "Parameter: image_encoder.layers.3.blocks.1.attn.qkv.bias - Different\n",
      "Parameter: image_encoder.layers.3.blocks.1.attn.proj.weight - Different\n",
      "Parameter: image_encoder.layers.3.blocks.1.attn.proj.bias - Different\n",
      "Parameter: image_encoder.layers.3.blocks.1.mlp.norm.weight - Different\n",
      "Parameter: image_encoder.layers.3.blocks.1.mlp.norm.bias - Different\n",
      "Parameter: image_encoder.layers.3.blocks.1.mlp.fc1.weight - Different\n",
      "Parameter: image_encoder.layers.3.blocks.1.mlp.fc1.bias - Different\n",
      "Parameter: image_encoder.layers.3.blocks.1.mlp.fc2.weight - Different\n",
      "Parameter: image_encoder.layers.3.blocks.1.mlp.fc2.bias - Different\n",
      "Parameter: image_encoder.layers.3.blocks.1.local_conv.c.weight - Different\n",
      "Parameter: image_encoder.layers.3.blocks.1.local_conv.bn.weight - Different\n",
      "Parameter: image_encoder.layers.3.blocks.1.local_conv.bn.bias - Different\n",
      "Parameter: image_encoder.layers.3.blocks.1.local_conv.bn.running_mean - Different\n",
      "Parameter: image_encoder.layers.3.blocks.1.local_conv.bn.running_var - Different\n",
      "Parameter: image_encoder.layers.3.blocks.1.local_conv.bn.num_batches_tracked - Different\n",
      "Parameter: image_encoder.neck.0.weight - Different\n",
      "Parameter: image_encoder.neck.1.weight - Different\n",
      "Parameter: image_encoder.neck.1.bias - Different\n",
      "Parameter: image_encoder.neck.2.weight - Different\n",
      "Parameter: image_encoder.neck.3.weight - Different\n",
      "Parameter: image_encoder.neck.3.bias - Different\n",
      "Parameter: mask_decoder.transformer.layers.0.self_attn.q_proj.weight - Different\n",
      "Parameter: mask_decoder.transformer.layers.0.self_attn.q_proj.bias - Different\n",
      "Parameter: mask_decoder.transformer.layers.0.self_attn.k_proj.weight - Different\n",
      "Parameter: mask_decoder.transformer.layers.0.self_attn.k_proj.bias - Different\n",
      "Parameter: mask_decoder.transformer.layers.0.self_attn.v_proj.weight - Different\n",
      "Parameter: mask_decoder.transformer.layers.0.self_attn.v_proj.bias - Different\n",
      "Parameter: mask_decoder.transformer.layers.0.self_attn.out_proj.weight - Different\n",
      "Parameter: mask_decoder.transformer.layers.0.self_attn.out_proj.bias - Different\n",
      "Parameter: mask_decoder.transformer.layers.0.norm1.weight - Different\n",
      "Parameter: mask_decoder.transformer.layers.0.norm1.bias - Different\n",
      "Parameter: mask_decoder.transformer.layers.0.cross_attn_token_to_image.q_proj.weight - Different\n",
      "Parameter: mask_decoder.transformer.layers.0.cross_attn_token_to_image.q_proj.bias - Different\n",
      "Parameter: mask_decoder.transformer.layers.0.cross_attn_token_to_image.k_proj.weight - Different\n",
      "Parameter: mask_decoder.transformer.layers.0.cross_attn_token_to_image.k_proj.bias - Different\n",
      "Parameter: mask_decoder.transformer.layers.0.cross_attn_token_to_image.v_proj.weight - Different\n",
      "Parameter: mask_decoder.transformer.layers.0.cross_attn_token_to_image.v_proj.bias - Different\n",
      "Parameter: mask_decoder.transformer.layers.0.cross_attn_token_to_image.out_proj.weight - Different\n",
      "Parameter: mask_decoder.transformer.layers.0.cross_attn_token_to_image.out_proj.bias - Different\n",
      "Parameter: mask_decoder.transformer.layers.0.norm2.weight - Different\n",
      "Parameter: mask_decoder.transformer.layers.0.norm2.bias - Different\n",
      "Parameter: mask_decoder.transformer.layers.0.mlp.lin1.weight - Different\n",
      "Parameter: mask_decoder.transformer.layers.0.mlp.lin1.bias - Different\n",
      "Parameter: mask_decoder.transformer.layers.0.mlp.lin2.weight - Different\n",
      "Parameter: mask_decoder.transformer.layers.0.mlp.lin2.bias - Different\n",
      "Parameter: mask_decoder.transformer.layers.0.norm3.weight - Different\n",
      "Parameter: mask_decoder.transformer.layers.0.norm3.bias - Different\n",
      "Parameter: mask_decoder.transformer.layers.0.norm4.weight - Different\n",
      "Parameter: mask_decoder.transformer.layers.0.norm4.bias - Different\n",
      "Parameter: mask_decoder.transformer.layers.0.cross_attn_image_to_token.q_proj.weight - Different\n",
      "Parameter: mask_decoder.transformer.layers.0.cross_attn_image_to_token.q_proj.bias - Different\n",
      "Parameter: mask_decoder.transformer.layers.0.cross_attn_image_to_token.k_proj.weight - Different\n",
      "Parameter: mask_decoder.transformer.layers.0.cross_attn_image_to_token.k_proj.bias - Different\n",
      "Parameter: mask_decoder.transformer.layers.0.cross_attn_image_to_token.v_proj.weight - Different\n",
      "Parameter: mask_decoder.transformer.layers.0.cross_attn_image_to_token.v_proj.bias - Different\n",
      "Parameter: mask_decoder.transformer.layers.0.cross_attn_image_to_token.out_proj.weight - Different\n",
      "Parameter: mask_decoder.transformer.layers.0.cross_attn_image_to_token.out_proj.bias - Different\n",
      "Parameter: mask_decoder.transformer.layers.1.self_attn.q_proj.weight - Different\n",
      "Parameter: mask_decoder.transformer.layers.1.self_attn.q_proj.bias - Different\n",
      "Parameter: mask_decoder.transformer.layers.1.self_attn.k_proj.weight - Different\n",
      "Parameter: mask_decoder.transformer.layers.1.self_attn.k_proj.bias - Different\n",
      "Parameter: mask_decoder.transformer.layers.1.self_attn.v_proj.weight - Different\n",
      "Parameter: mask_decoder.transformer.layers.1.self_attn.v_proj.bias - Different\n",
      "Parameter: mask_decoder.transformer.layers.1.self_attn.out_proj.weight - Different\n",
      "Parameter: mask_decoder.transformer.layers.1.self_attn.out_proj.bias - Different\n",
      "Parameter: mask_decoder.transformer.layers.1.norm1.weight - Different\n",
      "Parameter: mask_decoder.transformer.layers.1.norm1.bias - Different\n",
      "Parameter: mask_decoder.transformer.layers.1.cross_attn_token_to_image.q_proj.weight - Different\n",
      "Parameter: mask_decoder.transformer.layers.1.cross_attn_token_to_image.q_proj.bias - Different\n",
      "Parameter: mask_decoder.transformer.layers.1.cross_attn_token_to_image.k_proj.weight - Different\n",
      "Parameter: mask_decoder.transformer.layers.1.cross_attn_token_to_image.k_proj.bias - Different\n",
      "Parameter: mask_decoder.transformer.layers.1.cross_attn_token_to_image.v_proj.weight - Different\n",
      "Parameter: mask_decoder.transformer.layers.1.cross_attn_token_to_image.v_proj.bias - Different\n",
      "Parameter: mask_decoder.transformer.layers.1.cross_attn_token_to_image.out_proj.weight - Different\n",
      "Parameter: mask_decoder.transformer.layers.1.cross_attn_token_to_image.out_proj.bias - Different\n",
      "Parameter: mask_decoder.transformer.layers.1.norm2.weight - Different\n",
      "Parameter: mask_decoder.transformer.layers.1.norm2.bias - Different\n",
      "Parameter: mask_decoder.transformer.layers.1.mlp.lin1.weight - Different\n",
      "Parameter: mask_decoder.transformer.layers.1.mlp.lin1.bias - Different\n",
      "Parameter: mask_decoder.transformer.layers.1.mlp.lin2.weight - Different\n",
      "Parameter: mask_decoder.transformer.layers.1.mlp.lin2.bias - Different\n",
      "Parameter: mask_decoder.transformer.layers.1.norm3.weight - Different\n",
      "Parameter: mask_decoder.transformer.layers.1.norm3.bias - Different\n",
      "Parameter: mask_decoder.transformer.layers.1.norm4.weight - Different\n",
      "Parameter: mask_decoder.transformer.layers.1.norm4.bias - Different\n",
      "Parameter: mask_decoder.transformer.layers.1.cross_attn_image_to_token.q_proj.weight - Different\n",
      "Parameter: mask_decoder.transformer.layers.1.cross_attn_image_to_token.q_proj.bias - Different\n",
      "Parameter: mask_decoder.transformer.layers.1.cross_attn_image_to_token.k_proj.weight - Different\n",
      "Parameter: mask_decoder.transformer.layers.1.cross_attn_image_to_token.k_proj.bias - Different\n",
      "Parameter: mask_decoder.transformer.layers.1.cross_attn_image_to_token.v_proj.weight - Different\n",
      "Parameter: mask_decoder.transformer.layers.1.cross_attn_image_to_token.v_proj.bias - Different\n",
      "Parameter: mask_decoder.transformer.layers.1.cross_attn_image_to_token.out_proj.weight - Different\n",
      "Parameter: mask_decoder.transformer.layers.1.cross_attn_image_to_token.out_proj.bias - Different\n",
      "Parameter: mask_decoder.transformer.final_attn_token_to_image.q_proj.weight - Different\n",
      "Parameter: mask_decoder.transformer.final_attn_token_to_image.q_proj.bias - Different\n",
      "Parameter: mask_decoder.transformer.final_attn_token_to_image.k_proj.weight - Different\n",
      "Parameter: mask_decoder.transformer.final_attn_token_to_image.k_proj.bias - Different\n",
      "Parameter: mask_decoder.transformer.final_attn_token_to_image.v_proj.weight - Different\n",
      "Parameter: mask_decoder.transformer.final_attn_token_to_image.v_proj.bias - Different\n",
      "Parameter: mask_decoder.transformer.final_attn_token_to_image.out_proj.weight - Different\n",
      "Parameter: mask_decoder.transformer.final_attn_token_to_image.out_proj.bias - Different\n",
      "Parameter: mask_decoder.transformer.norm_final_attn.weight - Different\n",
      "Parameter: mask_decoder.transformer.norm_final_attn.bias - Different\n",
      "Parameter: mask_decoder.iou_token.weight - Different\n",
      "Parameter: mask_decoder.mask_tokens.weight - Different\n",
      "Parameter: mask_decoder.output_upscaling.0.weight - Different\n",
      "Parameter: mask_decoder.output_upscaling.0.bias - Different\n",
      "Parameter: mask_decoder.output_upscaling.1.weight - Different\n",
      "Parameter: mask_decoder.output_upscaling.1.bias - Different\n",
      "Parameter: mask_decoder.output_upscaling.3.weight - Different\n",
      "Parameter: mask_decoder.output_upscaling.3.bias - Different\n",
      "Parameter: mask_decoder.output_hypernetworks_mlps.0.layers.0.weight - Different\n",
      "Parameter: mask_decoder.output_hypernetworks_mlps.0.layers.0.bias - Different\n",
      "Parameter: mask_decoder.output_hypernetworks_mlps.0.layers.1.weight - Different\n",
      "Parameter: mask_decoder.output_hypernetworks_mlps.0.layers.1.bias - Different\n",
      "Parameter: mask_decoder.output_hypernetworks_mlps.0.layers.2.weight - Different\n",
      "Parameter: mask_decoder.output_hypernetworks_mlps.0.layers.2.bias - Different\n",
      "Parameter: mask_decoder.output_hypernetworks_mlps.1.layers.0.weight - Different\n",
      "Parameter: mask_decoder.output_hypernetworks_mlps.1.layers.0.bias - Different\n",
      "Parameter: mask_decoder.output_hypernetworks_mlps.1.layers.1.weight - Different\n",
      "Parameter: mask_decoder.output_hypernetworks_mlps.1.layers.1.bias - Different\n",
      "Parameter: mask_decoder.output_hypernetworks_mlps.1.layers.2.weight - Different\n",
      "Parameter: mask_decoder.output_hypernetworks_mlps.1.layers.2.bias - Different\n",
      "Parameter: mask_decoder.output_hypernetworks_mlps.2.layers.0.weight - Different\n",
      "Parameter: mask_decoder.output_hypernetworks_mlps.2.layers.0.bias - Different\n",
      "Parameter: mask_decoder.output_hypernetworks_mlps.2.layers.1.weight - Different\n",
      "Parameter: mask_decoder.output_hypernetworks_mlps.2.layers.1.bias - Different\n",
      "Parameter: mask_decoder.output_hypernetworks_mlps.2.layers.2.weight - Different\n",
      "Parameter: mask_decoder.output_hypernetworks_mlps.2.layers.2.bias - Different\n",
      "Parameter: mask_decoder.output_hypernetworks_mlps.3.layers.0.weight - Different\n",
      "Parameter: mask_decoder.output_hypernetworks_mlps.3.layers.0.bias - Different\n",
      "Parameter: mask_decoder.output_hypernetworks_mlps.3.layers.1.weight - Different\n",
      "Parameter: mask_decoder.output_hypernetworks_mlps.3.layers.1.bias - Different\n",
      "Parameter: mask_decoder.output_hypernetworks_mlps.3.layers.2.weight - Different\n",
      "Parameter: mask_decoder.output_hypernetworks_mlps.3.layers.2.bias - Different\n",
      "Parameter: mask_decoder.iou_prediction_head.layers.0.weight - Different\n",
      "Parameter: mask_decoder.iou_prediction_head.layers.0.bias - Different\n",
      "Parameter: mask_decoder.iou_prediction_head.layers.1.weight - Different\n",
      "Parameter: mask_decoder.iou_prediction_head.layers.1.bias - Different\n",
      "Parameter: mask_decoder.iou_prediction_head.layers.2.weight - Different\n",
      "Parameter: mask_decoder.iou_prediction_head.layers.2.bias - Different\n",
      "Parameter: prompt_encoder.pe_layer.positional_encoding_gaussian_matrix - Same\n",
      "Parameter: prompt_encoder.point_embeddings.0.weight - Same\n",
      "Parameter: prompt_encoder.point_embeddings.1.weight - Same\n",
      "Parameter: prompt_encoder.point_embeddings.2.weight - Different\n",
      "Parameter: prompt_encoder.point_embeddings.3.weight - Different\n",
      "Parameter: prompt_encoder.not_a_point_embed.weight - Same\n",
      "Parameter: prompt_encoder.mask_downscaling.0.weight - Same\n",
      "Parameter: prompt_encoder.mask_downscaling.0.bias - Same\n",
      "Parameter: prompt_encoder.mask_downscaling.1.weight - Same\n",
      "Parameter: prompt_encoder.mask_downscaling.1.bias - Same\n",
      "Parameter: prompt_encoder.mask_downscaling.3.weight - Same\n",
      "Parameter: prompt_encoder.mask_downscaling.3.bias - Same\n",
      "Parameter: prompt_encoder.mask_downscaling.4.weight - Same\n",
      "Parameter: prompt_encoder.mask_downscaling.4.bias - Same\n",
      "Parameter: prompt_encoder.mask_downscaling.6.weight - Same\n",
      "Parameter: prompt_encoder.mask_downscaling.6.bias - Same\n",
      "Parameter: prompt_encoder.no_mask_embed.weight - Different\n",
      "   .\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import os\n",
    "\n",
    "checkpoint_path_1 = '/home/minkyukim/sam-tinyViT/work_dir/MedSAM/lite_medsam.pth'\n",
    "checkpoint_path_2 = '/mnt/sda/minkyukim/pth/tiny-ivdm/tiny_model_best.pth'\n",
    "\n",
    "checkpoint_1 = torch.load(checkpoint_path_1, map_location='cpu')\n",
    "checkpoint_2 = torch.load(checkpoint_path_2, map_location='cpu')\n",
    "\n",
    "params_1 = checkpoint_1['state_dict'] if 'state_dict' in checkpoint_1 else checkpoint_1\n",
    "params_2 = checkpoint_2['state_dict'] if 'state_dict' in checkpoint_2 else checkpoint_2\n",
    "\n",
    "param_diff = {}\n",
    "for name in params_1.keys():\n",
    "    if name in params_2:\n",
    "        param_1 = params_1[name]\n",
    "        param_2 = params_2[name]\n",
    "        if torch.equal(param_1, param_2):\n",
    "            param_diff[name] = 'Same'\n",
    "        else:\n",
    "            param_diff[name] = 'Different'\n",
    "    else:\n",
    "        param_diff[name] = 'Only in checkpoint 1'\n",
    "\n",
    "for name in params_2.keys():\n",
    "    if name not in param_diff:\n",
    "        param_diff[name] = 'Only in checkpoint 2'\n",
    "\n",
    "for name, result in param_diff.items():\n",
    "    print(f'Parameter: {name} - {result}')\n",
    "\n",
    "print(\"   .\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "medsam",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
